\chapter{Budowa i działanie aplikacji}
\label{t:budowa}

	\section{Możliwości aplikacji}
	\label{t:budowa:mozliw}
	
	% co aplikacja robić może
	% rysować grafikę, oświetlenie phonga blinna, światło kierunkowe
	% rendering odroczony i system post-procesów
	% obsługa kamery i oglądanie sceny ze wszystkich stron
	% obliczanie oraz wyświetlanie statystyk i podpowiedzi
	
	Na potrzeby niniejszej pracy została stworzona aplikacja prezentacyjna. Jej głównym zadaniem jest wizualne zaprezentowanie działania omawianych technik kierunkowej okluzji otoczenia oraz pomiar ich wydajności. 
	
	W programie stworzona zostaje wirtualna scena, w której istnieje pewna geometria charakteryzująca się znaczącą liczbą kantów, zagięć oraz szczelin. Symuluje to wygląd typowej sceny w komercyjnych aplikacjach czasu rzeczywistego i stanowi dobre pole do przetestowania technik okluzji otoczenia. Powinna ona wystąpić w dużej liczbie miejsc, ponadto nachodzące na siebie obiekty pozwalają sprawdzić algorytmy pod kątem podatności na występowanie artefaktów. W scenie umieszczono także kilka kolorowych sześcianów, dzięki czemu łatwo jest przebadać i zobaczyć efekt występowania oświetlenia niebezpośredniego.
	
	Wszystkie obiekty oświetlone zostały światłem kierunkowym o ściśle określonym kolorze. Odbicie zwierciadlane obliczane jest przy użyciu równania Phonga-Blinna. Do modelu oświetlenia dodano także komponent \emph{ambient}, dzięki któremu nieoświetlone miejsca nie są kompletnie czarne i można zobaczyć efekt działania okluzji. Dodatkowo światło kierunkowe powoli obraca się wokół jednej z osi układu współrzędnych -- pozwala to na zaobserwowanie ruchu zacienienia i różnice między kierunkową a zwykłą okluzją otoczenia.
	
	Renderowana scena jest oprócz tego kompletnie statyczna, jednak przy użyciu myszy i~klawiatury użytkownik może swobodnie przemieszczać oraz obracać kamerę. Efekty działania algorytmów mogą być sprawdzone pod dowolnym kątem patrzenia, z dowolnego miejsca i odległości. Poza tym, wciskając odpowiedni klawisz, widz jest w stanie przełączać się pomiędzy efektami i dzięki temu może je porównywać dla tych samych ustawień kamery bez potrzeby resetowania aplikacji.
	
	Program posiada jeszcze jedną istotną cechę. Dzięki implementacji modułu rysowania tekstu istnieje możliwość wyświetlania na ekranie informacji istotnych z punktu widzenia omawianych zagadnień. Do takich zaliczają się m.in. czas potrzebny na narysowanie jednej pełnej ramki obrazu oraz liczba klatek renderowanych w okresie jednej sekundy. Ma to kluczowe znaczenie w kwestii badania wydajności, gdyż da się od ręki sprawdzić, która technika działa szybciej, a która wolniej. Wyświetlana jest także krótka informacja dla użytkownika, mówiąca mu o sterowaniu oraz czynnościach, jakie może wykonać w obrębie aplikacji.

	\section{Ogólna architektura aplikacji}
	\label{t:budowa:architektura}
	
	% UML Głównych komponentów
	% Opisy klas: System, Renderer, Scene
	% Mechanizm managementu zasobów
	
	Na rysunku \ref{fig_5_A} przedstawiono główne komponenty programu oraz zależności pomiędzy nimi. Przerywana strzałka biegnąca od klasy A do B oznacza, że klasa A korzysta z funkcji udostępnianych przez klasę B. Niepogrubiona nazwa klasy znaczy, iż jest ona singletonem. Przy oznaczeniu agregacji, jeżeli nie napisano inaczej, mowa o powiązaniu 1 -- 1.
	
	\myownfigure{Diagram przedstawiający główne moduły aplikacji.}{figures/fig_5_A.png}{0.4}{fig_5_A}
	
	Nadrzędną klasą programu jest klasa \texttt{System}. Jej główne zadanie to inicjalizacja wszystkich podsystemów oraz modułów, które wymagane są do pracy programu. Musi także stworzyć okno z odpowiednimi parametrami i przesłać jego uchwyt do singletona \texttt{Renderer}. Następnie utrzymuje główną pętlę aplikacji i wywołuje funkcje aktualizacji poszczególnych komponentów w odpowiedniej kolejności: najpierw obliczany jest nowy stan encji sceny, następnie zostaje narysowana ramka obrazu, po czym aktualizują się moduły \texttt{Timer} oraz \texttt{Input}. Klasa \texttt{System} odpowiada także za komunikację z systemem operacyjnym i odbieranie jego komunikatów przy użyciu metody WINAPI \texttt{PeekMessage}. Obsługiwane są takie wydarzenia jak zamknięcie aplikacji, ustawienie kursora (jest wyłączany) czy aktualizacja danych z API RawInput.
	
	Singleton \texttt{Renderer} odpowiada przede wszystkim za inicjalizację oraz poprawne skonfigurowanie urządzenia Direct3D. Jego główną rolą w cyklu działania aplikacji jest udostępnianie interfejsów Direct3D -- \texttt{ID3D11Device}, służącego do tworzenia i niszczenia zasobów oraz stanów renderingu, oraz \texttt{ID3D11DeviceContext}, przy pomocy którego aplikacja może ustawiać zasoby dla poszczególnych sekcji potoku renderingu oraz wywoływać funkcje rysujące i obliczeniowe. \texttt{Renderer} przechowuje także zestaw domyślnie skonfigurowanych stanów mieszania buforów i umożliwia szybkie przełączanie się między nimi, bez konieczności tworzenia ich podczas cyklu programu.
	
	Kluczowy element całego programu to klasa \texttt{Scene}. Przechowywane są tam wszystkie encje systemu, których logika jest obliczana i aktualizowana w pierwszym kroku pętli programu. W skład encji wchodzą m.in. \emph{obiekty} (klasa \texttt{Object}), będące po prostu statycznymi elementami sceny, złożonymi z siatki wielokątowej oraz materiału. Istotnym składnikiem klasy \texttt{Scene} są różne rodzaje oświetlenia. Aplikacja obsługuje światła \emph{ambient}, kierunkowe i punktowe, jednak te ostatnie nie mają zastosowania w~niniejszym projekcie, gdyż w implementacji nie są związane z efektem kierunkowej okluzji otoczenia. Taka sytuacja ma miejsce, ponieważ jest ona zależna od konkretnego kierunku oraz koloru światła. Oznacza to, że należałoby dokonać oddzielnych obliczeń dla każdego źródła światła w scenie, czego koszt mógłby być niewspółmierny do efektu wizualnego. Z tego względu zdecydowano się ograniczyć oświetlenie sceny tylko do jednego światła kierunkowego, które powiązano z SSDO. W praktyce oczywiście mogłoby istnieć dużo więcej różnego rodzaju źródeł światła, jednak tylko jedno miałoby wpływ na okluzję.
	
	Kolejne składniki \texttt{Scene} to post-procesy (klasa abstrakcyjna \texttt{Postprocess} i klasy z niej dziedziczące) oraz teksty (klasa \texttt{Text}). Te dwa rodzaje elementów system rysuje już po wyrenderowaniu i~oświetleniu całej sceny. Najistotniejszym jej składnikiem jest jednak kamera (klasa \texttt{Camera}). To ona określa, z którego miejsca i z jakimi parametrami będą rysowane encje. Wraz z klasą \texttt{GBuffer}, zawiera w sobie także implementację renderingu odroczonego, dokładniej opisanego w podrozdziale \ref{t:budowa:rendering:rendering}.
	
	W omawianym projekcie \texttt{Scene} pełni także rolę menedżera zasobów. Zaliczają się do nich shadery (rozumiane jako komplety zestaw programów cieniujących oraz buforów stałych dla pojedynczego wywołania potoku renderingu), shadery obliczeniowe (rozróżniane z racji na inne sposoby wywołania oraz zastosowania), siatki wielokątowe, materiały i fonty. Każdy rodzaj zasobu znajduje się w odpowiadającym mu słowniku, gdzie rolę kluczy pełnią ciągi znaków -- ścieżki do plików na dysku. Kiedy występuje odwołanie do danego obiektu poprzez ścieżkę, najpierw zostaje sprawdzone, czy zasób o takiej ścieżce nie został już załadowany. Jeśli tak, zostaje zwrócony wskaźnik do niego. W przeciwnym wypadku następuje proces wczytania i umieszczeniu w słowniku. Przy wyłączeniu programu słowniki są czyszczone a~ich elementy usuwane. Dzięki temu inne moduły nie muszą przejmować się tym, czy zasób został wczytany, nie muszą także brać pod uwagę konieczności zwolnienia go.
	
	Ostatnim z istotnych składników sceny jest kontroler (klasa \texttt{Controller}). Korzystając z modułów \texttt{Timer} oraz \texttt{Input} zarządza on działaniem aplikacji. Odpowiada za logikę sterowania kamerą przez użytkownika oraz ustawianie i aktualizowanie wszystkich tekstów na ekranie. Za jego pomocą można także przełączać się między post-procesami. Dba on o~to, by jednocześnie aktywny był tylko jeden.
	
	\section{Działanie głównych modułów}
	\label{t:budowa:rendering}
			
		% UML zależności pomiędzy klasami Renderer, Camera, Scene i GBuffer
	
		Na rysunku \ref{fig_5_B} przedstawiono główne komponenty modułu renderingu oraz przepływ sterowania pomiędzy nimi.
		
		\myownfigure{Diagram przedstawiający elementy modułu renderingu.}{figures/fig_5_B.png}{0.4}{fig_5_B}
	
		\subsection{Rendering odroczony}
		\label{t:budowa:rendering:rendering}
		
		% Opisy mechanizmu działania Camera i GBuffer
		% Mieszanie oświetlenia z buforem
		% Pipeline G-Bufora
		% Pipeline shaderów
		
		Zastosowanie renderingu odroczonego (\emph{deferowanego}) w niniejszej aplikacji zostało podyktowane faktem, iż duża część danych uzyskiwana w tym procesie potrzebna jest do realizacji omawianych technik kierunkowej okluzji otoczenia, na przykład bufor wektorów normalnych i głębokości. Klasy \texttt{Camera} i \texttt{GBuffer} zawierają w sobie implementację renderingu odroczonego. Pierwsza z nich jako argument funkcji \texttt{Draw} otrzymuje wskaźnik do obiektu klasy \texttt{Scene}. Jest też jej klasą zaprzyjaźnioną, co pozwala na łatwy dostęp do wszystkich potrzebnych składników.
		
		Najistotniejszym elementem kamery jest jej G-Bufor. To zestaw buforów służących do obliczeń oświetlenia w procesie renderingu odroczonego, a w dalszej kolejności -- także i~post-procesów. Na początku procesu rysowania jako cele renderingu zostają ustawione bufory koloru oraz wektorów normalnych i okluzji (funkcja \texttt{G-Buffera} \texttt{SetDrawMeshes}). Dwa ostatnie elementy mieszczą się w jednym buforze, jako iż razem stanowią wektor o~czterech komponentach. Następnie wszystkie obiekty sceny są renderowane, wypełniając danymi ustawione bufory. Kolejny krok to narysowanie na nich oświetlenia. Dla każdego rodzaju światła zostaje ustawiony odpowiedni program cieniujący, po czym następuje rendering wszystkich świateł tego typu, tzn. obliczenie ich równań dla każdego piksela ekranu. Dane wejściowe to bufory będące w poprzednim kroku obiektami wyjściowymi. Na podobnej zasadzie zostaje wykonane rysowanie post-procesów oraz tekstów, opisane bliżej w~podrozdziałach \ref{t:budowa:rendering:postprocesy} i \ref{t:budowa:inne:fonty}.
		
		Należy zauważyć, że w takim podejściu po stronie shaderów zawartych w G-Buforze znajduje się obowiązek implementacji modelu oświetlenia. W przypadku renderingu wprost (\emph{forwardowego}) tę funkcję posiadają shadery znajdujące się w materiałach, a co za tym idzie -- przypisane do rysowanych obiektów.
		
		\subsection{Post-procesy}
		\label{t:budowa:rendering:postprocesy}
		
		% Opis klasy Postprocess i przykłady jej użycia w klasach potomnych
		% Shadery postprocesowe - generowanie vertexów
		
		Post-procesy to funkcje pracujące na wyrenderowanych uprzednio buforach G-Bufora i generujące określony efekt graficzny w przestrzeni ekranu. Algorytm obliczany jest na GPU, zazwyczaj osobno dla każdego piksela przy użyciu pixel shaderów lub compute shaderów. Za implementację tych technik w omawianej aplikacji odpowiada klasa abstrakcyjna \texttt{Postprocess}, definiująca interfejs niezbędny do komunikacji z G-Buforem.
		
		Obiekt klasy \texttt{Postprocess} posiada zawsze swój zestaw shaderów wczytywanych przy inicjalizacji oraz trzy istotne funkcje -- \texttt{SetPass}, \texttt{AfterPass} i \texttt{Update}. Dwie pierwsze są wywoływane w procesie rysowania, a trzecia poza nim -- służy do wykonywania obliczeń niezwiązanych bezpośrednio z renderingiem.
		
		Rozpoczynając rysowanie post-procesów G-Bufor m.in. wyłącza ustawione poprzednio cele renderingu oraz ustawia na wejściu bazowe bufory, tzn. koloru, wektorów normalnych i~głębokości. Zostają dla nich także wygenerowane mipmapy, gdyż jest to potrzebne do implementacji algorytmów SSDO-B i SSDO-C. Następnie dla każdego post-procesu wywołana jest jego funkcja \texttt{SetPass}, przygotowująca dane i ustalająca wejścia shadera. Później ma miejsce rysowanie. Metoda \texttt{AfterPass} może być implementowana przez post-proces jeżeli wymaga on przeprowadzenia jakichś operacji po samym renderingu. Całość zostaje powtórzona tyle razy, ile post-proces deklaruje przebiegów. Przy ostatnim przebiegu zostają zamienione miejscami bufory wyjściowe tak, by finalny efekt rysowania trafił do bufora końcowego.
		
		G-Bufor zapewnia post-procesom zestaw dodatkowych buforów, przydatnych kiedy mają więcej niż jeden przebieg. Ich rozmiary są równe połowie rozmiarów tylnego bufora, co powoduje niewielkie pogorszenie finalnej jakości obrazu przy znaczącym zwiększeniu wydajności.
		
		Warto wspomnieć o czynionej przy okazji procesu renderingu post-procesów niewielkiej optymalizacji. Funkcja \texttt{Draw} Direct3D zostaje wywołana bez przypisanego bufora wierzchołków, natomiast w argumencie podana jest liczba 3. W shaderze wierzchołków następuje zastosowanie prostego algorytmu \cite{build01}, który polega na wygenerowaniu pełnoekranowego trójkąta, wypełniającego całą przestrzeń obrazu. Zysk następuje w dwóch miejscach -- po pierwsze nie dowiązuje się bufora i nie trzeba pobierać z niego danych. Po drugie, rysując trójkąt zamiast czworokąta można uniknąć obniżenia wydajności związanego z rasteryzacją, występującego na krawędzi dwóch trójkątów biegnącej wzdłuż przekątnej ekranu. Zbędne fragmenty pełnoekranowego trójkąta zostają obcięte przez test nożyc.
	
	\section{Działanie pozostałych modułów}
	\label{t:budowa:inne}
	
		\subsection{Pomiary wydajności}
		\label{t:budowa:inne:profiling}
		
		% Opis działania profilera i mechanizmu pobierania czasu w Timerze
		
		Pomiary wydajności są ściśle związane z klasą \texttt{Timer} i mechanizmem pobierania aktualnego czasu systemu. W tym celu wykorzystane zostały funkcje \texttt{QueryPerformanceCounter} i \texttt{QueryPerformanceFrequency} biblioteki WINAPI. Pozwalają one pobrać odpowiednio aktualny czas systemu w cyklach zegara procesora oraz częstotliwość jego pracy. Obie wartości cechuje bardzo duża precyzja. Dzieląc jedną przez drugą otrzymuje się czas procesora w sekundach. Dzięki temu łatwo jest obliczyć czas potrzebny na wygenerowanie jednej ramki obrazu oraz liczbę rysowanych ramek w ciągu sekundy.
		
		Jako składnik klasy \texttt{Controller} istnieje także klasa \texttt{Profiler}. Odpowiada ona za gromadzenie obliczanych przez \texttt{Timer} wyników i wyświetlanie ich na ekranie w formie liczbowej. Służy także do ich uśredniania, aby zapobiec skokowym, szybkim zmianom wprowadzającym użytkownika w błąd i utrudniającym dokonanie pomiarów wydajności.
	
		\subsection{Obsługa kontrolerów}
		\label{t:budowa:inne:input}
		
		% Opis działania klasy Input i obsługi biblioteki RawInput
		
		Klasa \texttt{Input} odpowiada za odbieranie i przetwarzanie danych pochodzących z urządzeń wejścia-wyjścia. W przypadku omawianej aplikacji obsługiwana jest klawiatura i mysz. Aby uzyskać do nich dostęp użyto funkcji WINAPI \texttt{RegisterRawInputDevices}. Jako argumenty przyjmuje ona wskaźnik do tablicy struktur \texttt{RAWINPUTDEVICE}, liczbę elementów oraz rozmiar jednego z nich. Za pomocą struktury określa się tzw. \emph{usage page} i \emph{usage} czyli to, jakiego rodzaju i jakie urządzenie zostanie powiązane z programem \cite{tech03}. 
		Dane od biblioteki RawInput pobierane są jako jeden z komunikatów systemu operacyjnego, o~sygnaturze \texttt{WM\_INPUT}. Kiedy funkcja przetwarzająca wiadomości trafi na nią, oznacza to, że jednym z parametrów jest obiekt struktury \texttt{HRAWINPUT}. Zostaje on przesłany do obiektu klasy \texttt{Input}, która wyciąga z~niego informacje dotyczące aktualnego stanu klawiszy, przycisków oraz położenia myszy, a~także jej rolki.
		
		\subsection{Rysowanie fontów}
		\label{t:budowa:inne:fonty}
		
		% Opis mechanizmu wczytywania fontów, generowania tekstur oraz meshy i rysowania ich na ekranie
		
		Ostatnim istotnym mechanizmem omawianej aplikacji jest rysowanie fontów niezbędne do wyświetlania na ekranie statystyk oraz wiadomości. Została w tym celu wykorzystana biblioteka FreeType. Wykonuje ona szereg czynności, począwszy od wczytania pliku czcionki w formacie wektorowym i na bazie zdefiniowanych ustawień, przekształcenia w~jednokanałową ośmiobitową bitmapę. Program następnie pobiera jej fragmenty i kopiuje do wynikowej tekstury, przy okazji generując dane przesunięć.
		
		Każdy obiekt klasy \texttt{Text} zawiera w sobie pewien ciąg znaków. Na bazie tego i przy użyciu danych przesunięć, w obiekcie klasy \texttt{Mesh} generowane są wierzchołki i koordynaty teksturowania. Taka siatka wielokątowa zostaje później narysowana na ekranie korzystając z wspomnianej wyżej wynikowej tekstury fontu, parametru koloru oraz przesunięcia i skali. Przy każdej zmianie tekstu zawartość obiektu \texttt{Mesh} należy wygenerować od nowa.